{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangling OpenStreetMap Data Project\n",
    "Window10_64-bit OS, Python 2.7, Anaconda2\n",
    "## June 2017, by Jude Moon\n",
    "***\n",
    "## Map Area\n",
    "Blacksburg, VA, USA\n",
    "\n",
    "* https://www.openstreetmap.org/relation/206542\n",
    "\n",
    "I went to school here and am living in this area since then. This is the area where I am the most familiar with street names and locations so I thought it would be a good starting point.\n",
    "\n",
    "# 1. Data Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "#import pandoc # to convert ipynb to pdf\n",
    "import pprint\n",
    "import audit # modularized py script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'bburg_map.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many tag elements?\n",
      "819599\n",
      "\n",
      "How many of each tag element?\n",
      "{'bounds': 1,\n",
      " 'member': 11083,\n",
      " 'meta': 1,\n",
      " 'nd': 281754,\n",
      " 'node': 270918,\n",
      " 'note': 1,\n",
      " 'osm': 1,\n",
      " 'relation': 387,\n",
      " 'tag': 233712,\n",
      " 'way': 21741}\n"
     ]
    }
   ],
   "source": [
    "total_tags = audit.count_tags(filename)\n",
    "print \"How many tag elements?\"\n",
    "print sum(total_tags.values())\n",
    "\n",
    "print \"\\nHow many of each tag element?\"\n",
    "pprint.pprint(total_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag_keys = audit.count_tag_keys(filename)\n",
    "print \"\"\"Among tag elements, there are tag elements with the name 'tag'.\n",
    "What are the unique key name of 'tag' elements?\"\"\"\n",
    "pprint.pprint(tag_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: this output of this cell was cleared because of the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique key names appear at 'tag' elements:\n",
      "367\n",
      "Number of total keys appear at 'tag' elements:\n",
      "233712\n",
      "Number of total 'tag'' elements:\n",
      "233712\n"
     ]
    }
   ],
   "source": [
    "print \"Number of unique key names appear at 'tag' elements:\"\n",
    "print len(tag_keys)\n",
    "\n",
    "print \"Number of total keys appear at 'tag' elements:\"\n",
    "print sum(tag_keys.values())\n",
    "\n",
    "print \"Number of total 'tag'' elements:\"\n",
    "print total_tags['tag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: There are uppercase, lowercase, mixedcase keys. And some keys have number, one or two underscore( _ ), one or two colons( : ). \n",
    "\n",
    "Note that a lot of keys with colons share the same words before colons so this implies the hierarchical structures for key names. The solution would be breaking down into two columns for key names.\n",
    "\n",
    "I want to categorize the tag keys into 4 types:\n",
    "- \"whthout_colons\" for tags that contain letters(ignore case), number, and underscore and are valid,\n",
    "- \"with_colons\" for otherwise with one or more colons in their names,\n",
    "- \"problemchars\" for tags with space or problematic characters, and\n",
    "- \"other\" for other tags that do not fall into the other three categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many problematic key names?\n",
      "{'other': 1, 'problemchars': 1, 'with_colons': 182620, 'without_colons': 51090}\n",
      "\n",
      "\n",
      "Number of total keys appear at tag element:\n",
      "233712\n"
     ]
    }
   ],
   "source": [
    "tag_keys_types = audit.count_key_types(filename)\n",
    "\n",
    "print \"How many problematic key names?\"\n",
    "pprint.pprint(tag_keys_types)\n",
    "print '\\n'\n",
    "print 'Number of total keys appear at tag element:'\n",
    "print sum(tag_keys_types.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show me the problematic key names:\n",
      "set(['permanently closed'])\n",
      "\n",
      "\n",
      "Show me the other key names:\n",
      "set(['his:1973-:power'])\n"
     ]
    }
   ],
   "source": [
    "tag_keys_names = audit.key_type(filename)\n",
    "\n",
    "print \"Show me the problematic key names:\"\n",
    "pprint.pprint(tag_keys_names['problemchars'])\n",
    "print '\\n'\n",
    "print \"Show me the other key names:\"\n",
    "pprint.pprint(tag_keys_names['other'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show me the street types:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Avenue',\n",
       " 'Boulevard',\n",
       " 'Circle',\n",
       " 'Court',\n",
       " 'Crossing',\n",
       " 'Drive',\n",
       " 'Lane',\n",
       " 'North',\n",
       " 'Northeast',\n",
       " 'Northwest',\n",
       " 'Pass',\n",
       " 'Place',\n",
       " 'Road',\n",
       " 'Run',\n",
       " 'South',\n",
       " 'Southwest',\n",
       " 'Square',\n",
       " 'Street',\n",
       " 'Terrace',\n",
       " 'Trail',\n",
       " 'Way'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Show me the street types:\"\n",
    "audit.get_street_types(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Street types are consistent in this map, which all are in full name, not in abbreviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many users?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"How many users?\"\n",
    "len(audit.get_user(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Problems Encountered in the Map\n",
    "\n",
    "* Uppercase tag keys: I changed regex to match uppercase as well as lowercase\n",
    "    \n",
    "        NHD:ComID\n",
    "    \n",
    "    \n",
    "* Number in tag keys : I changed regex to match letters with _number, but this will not be reflected for cleaning process because separating the number from the key does not seem advantageous\n",
    "    \n",
    "        amenity_1\n",
    "\n",
    "* Two colons in the keys: I changed regex to match one or more colons, so first word before the first colon becomes 'type' key and the rest of string becomes 'key'\n",
    "\n",
    "        destination:ref:to -> {'type':'destination', 'key':'ref:to'}\n",
    "        \n",
    "        The benefit of this change is that we can analyze and make summary on nested key levels. But anticipated issues would be that too many nested keys can be unique keys that will not help to summarize any meaningful information, but increase noise on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Overview\n",
    "\n",
    "## File sizes:\n",
    "- bburg_map.xml: 60.851MB\n",
    "- bburg_nodes.csv: 22.205MB\n",
    "- bburg_nodes_tag.csv: 5.346MB\n",
    "- bburg_ways.csv: 1.27MB\n",
    "- bburg_ways_nodes.csv: 6.148MB\n",
    "- bburg_ways_tags.csv: 2.086MB\n",
    "- bburg_map.db: 33.184MB\n",
    "***\n",
    "## Number of nodes:\n",
    "sqlite> SELECT COUNT(*) FROM nodes;\n",
    "\n",
    "    270918\n",
    "***\n",
    "## Number of ways:\n",
    "sqlite> SELECT COUNT(*) FROM ways;\n",
    "\n",
    "    21741\n",
    "***\n",
    "## Number of unique users:\n",
    "sqlite> SELECT COUNT(DISTINCT(e.uid))          \n",
    "FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e;\n",
    "\n",
    "    264\n",
    "\n",
    "***\n",
    "# 4. Data Exploration \n",
    "\n",
    "## Top 10 contributing users:\n",
    "sqlite> SELECT e.user, COUNT(*) as num          \n",
    "FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e          \n",
    "GROUP BY e.user          \n",
    "ORDER BY num DESC          \n",
    "LIMIT 10;          \n",
    "\n",
    "    mutantmonkey|156773\n",
    "    jumbanho|48958\n",
    "    Evanator|28366\n",
    "    dcat|17114\n",
    "    woodpeck_fixbot|9489\n",
    "    Spesh|4458\n",
    "    jbvejle|2743\n",
    "    Chris Lawrence|2415\n",
    "    Dayton_Poff|2161\n",
    "    bdiscoe|1831\n",
    "***    \n",
    "## Number of users appearing only once (having 1 post):\n",
    "sqlite> SELECT COUNT(*)           \n",
    "FROM          \n",
    "(SELECT e.user, COUNT(*) as num          \n",
    "FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e          \n",
    "GROUP BY e.user          \n",
    "HAVING num=1)  u;          \n",
    "\n",
    "    47\n",
    "***    \n",
    "## Top 10 appearing amenities:\n",
    "sqlite> SELECT value, COUNT(*) as num           \n",
    "FROM nodes_tags           \n",
    "WHERE key='amenity'           \n",
    "GROUP BY value           \n",
    "ORDER BY num DESC           \n",
    "LIMIT 10;\n",
    "    \n",
    "    bench|187\n",
    "    recycling|169\n",
    "    bicycle_parking|141\n",
    "    restaurant|51\n",
    "    place_of_worship|43\n",
    "    fast_food|32\n",
    "    school|25\n",
    "    fuel|18\n",
    "    grave_yard|17\n",
    "    shelter|17\n",
    "***\n",
    "## Biggest religion:\n",
    "\n",
    "sqlite> SELECT nodes_tags.value, COUNT(*) as num           \n",
    "FROM nodes_tags            \n",
    "JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='place_of_worship') i           \n",
    "ON nodes_tags.id=i.id           \n",
    "WHERE nodes_tags.key='religion'           \n",
    "GROUP BY nodes_tags.value           \n",
    "ORDER BY num DESC           \n",
    "LIMIT 1;           \n",
    "\n",
    "    christian|41\n",
    "***    \n",
    "## Most popular cuisines:\n",
    "\n",
    "sqlite> SELECT nodes_tags.value, COUNT(*) as num           \n",
    "FROM nodes_tags            \n",
    "JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='restaurant') i           \n",
    "ON nodes_tags.id=i.id           \n",
    "WHERE nodes_tags.key='cuisine'           \n",
    "GROUP BY nodes_tags.value           \n",
    "ORDER BY num DESC;    \n",
    "    \n",
    "    chinese|4\n",
    "    mexican|4\n",
    "    american|3\n",
    "    pizza|3\n",
    "    regional|3\n",
    "    italian|2\n",
    "    sandwich|2\n",
    "    Lebanese|1\n",
    "    brazilian|1\n",
    "    ethiopian|1\n",
    "    fine_dining|1\n",
    "    greek|1\n",
    "    hibachi|1\n",
    "    ice_cream|1\n",
    "    japanese|1\n",
    "    sushi|1\n",
    "    thai|1\n",
    "    vegetarian|1\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Other ideas about the dataset\n",
    "\n",
    "The map data in Blacksburg area were relatively clean overall, but as I looked into summary of columns, there were marginal errors (see other problems). \n",
    "\n",
    "One thing that I am suspicious about the map data is no postal code of 24061 which is Virginia Tech zip code. Because Blacksburg is Virginia Tech driven town, I would think that there is a good number of nodes associated with the University (about 400). But I found one zip code of 24061-9517, so this totally doesn't make sense. Plus, the total number of postal code info (about 100) is very small with the population of 8 million. This could have happened because users input the address without postal code or they don't separate it into a tag for postal code.\n",
    "\n",
    "This could be solved by having users' rules or instructions that show requirements of fields and if it does not include all the required information, notify the users or show a red flag of incomplete inputs.\n",
    "\n",
    "## other problems\n",
    "* Inconsistency in Postal code\n",
    "    \n",
    "        24060-3348|1\n",
    "        24061-9517|1\n",
    "        VA 24060|1\n",
    "    \n",
    "    \n",
    "* Numbers in city name\n",
    "        10|9\n",
    "        14|9\n",
    "        22|6\n",
    "        24|6\n",
    "        \n",
    "* Inconsistency of case in city name\n",
    "        CHRISTIANSBURG|2\n",
    "        christiansburg|2\n",
    "        \n",
    "* Wrong category in city name\n",
    "        Virginia|2\n",
    "        \n",
    "\n",
    "### Post Codes:\n",
    "sqlite> SELECT tags.value, COUNT(*) as count            \n",
    "FROM (SELECT * FROM nodes_tags            \n",
    "\t  UNION ALL            \n",
    "      SELECT * FROM ways_tags) tags           \n",
    "WHERE tags.key='postcode'           \n",
    "GROUP BY tags.value           \n",
    "ORDER BY count DESC;           \n",
    "\n",
    "    24060|63\n",
    "    24073|58\n",
    "    24060-3348|1\n",
    "    24061-9517|1\n",
    "    VA 24060|1\n",
    "***    \n",
    "### Cities:\n",
    "\n",
    "sqlite> SELECT tags.value, COUNT(*) as count       \n",
    "FROM (SELECT * FROM nodes_tags UNION ALL       \n",
    "      SELECT * FROM ways_tags) tags      \n",
    "WHERE tags.key LIKE '%city'      \n",
    "GROUP BY tags.value      \n",
    "ORDER BY count DESC;      \n",
    "\n",
    "    Blacksburg|16243\n",
    "    Christiansburg|67\n",
    "    10|9\n",
    "    14|9\n",
    "    22|6\n",
    "    24|6\n",
    "    6|6\n",
    "    2|5\n",
    "    4|5\n",
    "    18|3\n",
    "    20|3\n",
    "    1176|2\n",
    "    2316|2\n",
    "    32|2\n",
    "    40|2\n",
    "    44|2\n",
    "    61|2\n",
    "    8|2\n",
    "    CHRISTIANSBURG|2\n",
    "    Virginia|2\n",
    "    christiansburg|2\n",
    "    110|1\n",
    "    \n",
    "***\n",
    "### Operator by Virginia Tech:\n",
    "\n",
    "sqlite> SELECT nodes_tags.key, nodes_tags.value, COUNT(*) \n",
    "FROM nodes_tags JOIN nodes \n",
    "ON nodes_tags.id=nodes.id\n",
    "WHERE (nodes_tags.key= 'operator') and (nodes_tags.value='Virginia Tech');\n",
    "\n",
    "        operator|Virginia Tech|400\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Conclusion\n",
    "\n",
    "Wrangling dataset on the open street map of Blacksburg was interesting process. But I would be more vigorously investigate the dataset if I had particular questions about the data up front. It is hard to tell why I need to wrangle this dataset, what kind of information I need to extract, and which keys and values I should spend more time to investigate. The vague idea of improving the dataset overall was not helpful. If I do this process next time, I will make clear goals in uses of database I am working on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Files\n",
    "- bburg_map.xml: osm file renamed with xml extension\n",
    "- audit.py: modularized py script including procedures used in this Jupyter Notebook\n",
    "- process.py: standalone py script parsing/cleaning/shaping and converting document tree to 5 separated csv files\n",
    "- map_schema.py: modularized py script including data schema for tabular format, used in process.py \n",
    "- db.py: standalone py script building database with 5 tables from 5 csv files\n",
    "- wrangling_osm_project_answers.ipynb: this document answering to the rubric questions\n",
    "- wrangling_osm_project_answers.html: html version of this document\n",
    "- wrangling_osm_project_answers.pdf: pdf printed of html answer file\n",
    "\n",
    "\n",
    "\n",
    "# 8. Sources\n",
    "- osm documentation: https://wiki.openstreetmap.org/wiki/Main_Page\n",
    "- unzip osm file: http://www.e7z.org/open-bz2-bzip2.htm\n",
    "- ET.iterparse, root.clear: http://effbot.org/zone/element-iterparse.htm\n",
    "- install new package in Anaconda: https://www.youtube.com/watch?v=_oNQKcNlBZs\n",
    "- familarize with abbreviation of street type in US: http://www.gis.co.clay.mn.us/usps.htm\n",
    "- reducing memory footprint: https://discussions.udacity.com/t/reducing-memory-footprint-when-processing-large-datasets-in-xml/37571/3\n",
    "- yield generator: https://pythontips.com/2013/09/29/the-python-yield-keyword-explained/"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
